{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae415ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiser17/anaconda3/envs/patra2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from shutil import copyfile\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from visualize_IG import *\n",
    "from utils_IG import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from smooth_grad.gradients import VanillaGrad, SmoothGrad, GuidedBackpropGrad, GuidedBackpropSmoothGrad\n",
    "from smooth_grad.image_utils import preprocess_image, save_as_gray_image\n",
    "from smooth_grad.labels import IMAGENET_LABELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c596755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))\n",
    "from cartoonX import CartoonX \n",
    "from pixelRDE import PixelRDE\n",
    "from utils_IG import calculate_outputs_and_gradients, generate_entrie_images\n",
    "from Integrated_grad import random_baseline_integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad122d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_LIST = tuple(open(os.path.join(sys.path[0], \"imagenet_labels.txt\")).read().split('\\n'))\n",
    "LABEL_LIST = [x.replace('{',\"\").replace('\\'',\"\").replace(',',\"\").replace('-',\" \").replace('_',\" \") for x in LABEL_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa51ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('random_images/')\n",
    "imgdir='random_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125b8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get classifier to explain\n",
    "model = models.mobilenet_v3_small(pretrained=True).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb2b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sys.path[0], \"hparams.yaml\")) as f:\n",
    "    HPARAMS_CARTOONX = yaml.load(f, Loader=yaml.FullLoader)[\"CartoonX\"]\n",
    "\n",
    "with open(os.path.join(sys.path[0], \"hparams.yaml\")) as f:\n",
    "    HPARAMS_PIXEL_RDE = yaml.load(f, Loader=yaml.FullLoader)[\"PixelRDE\"]\n",
    "\n",
    "# Initialize wavelet RDE and pixel RDE\n",
    "cartoonX = CartoonX(model=model, device=device, **HPARAMS_CARTOONX)\n",
    "pixelRDE = PixelRDE(model=model, device=device, **HPARAMS_PIXEL_RDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a435fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_largest_index_argsort(a, k):\n",
    "    idx = np.argsort(a.ravel())[:-k-1:-1]\n",
    "    return np.column_stack(np.unravel_index(idx, a.shape))\n",
    "\n",
    "def createmaskedimage(img,grad,percent,noise):\n",
    "    #grad:L X B\n",
    "    num_pixels=int(grad.shape[0]*grad.shape[1]*percent)\n",
    "    mask=np.zeros((grad.shape[0],grad.shape[1]))\n",
    "    topk_idx=k_largest_index_argsort(grad,num_pixels)\n",
    "    mask[topk_idx[:,0],topk_idx[:,1]]=1\n",
    "    mask=torch.tensor(mask).unsqueeze(0).unsqueeze(0).to(device)#1 X 1 X L X B\n",
    "    noise=torch.randn(img.shape)\n",
    "    new_img=img*mask+torch.clip(noise.to(device)*(1-mask),0,1)\n",
    "    return(mask,new_img)\n",
    "\n",
    "def save_as_gray_image(img, filename, percentile=99):#smoothgrad\n",
    "    img_2d = np.sum(img, axis=0)\n",
    "    span = abs(np.percentile(img_2d, percentile))\n",
    "    vmin = -span\n",
    "    vmax = span\n",
    "    img_2d = np.clip((img_2d - vmin) / (vmax - vmin), -1, 1)\n",
    "    cv2.imwrite(filename, img_2d * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64980af",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_list=list(np.array(list(range(0,101)))/100)\n",
    "full_array=torch.zeros((len(files),len(percent_list)))\n",
    "full_array_smooth=torch.zeros((len(files),len(percent_list)))\n",
    "full_array_cartoon=torch.zeros((len(files),len(percent_list)))\n",
    "full_array_randomwavelet=torch.zeros((len(files),len(percent_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c0e7f",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e1ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Integrated Gradients\n",
    "\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    # Get image and transform to tensor    \n",
    "    img = cv2.imread(os.path.join(imgdir, fname))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) \n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    # calculate the gradient and the label index\n",
    "    gradients, label_index = calculate_outputs_and_gradients([img], model, None, True)\n",
    "    gradients = np.transpose(gradients[0], (1, 2, 0))\n",
    "    attributions = random_baseline_integrated_gradients(img, model, label_index, calculate_outputs_and_gradients, \\\n",
    "                                                        steps=100, num_random_trials=10, cuda=True)\n",
    "\n",
    "    \n",
    "    input_img = pre_processing(img, True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            noise=torch.randn(input_img.shape)\n",
    "            mask_,masked_img=createmaskedimage(input_img,attributions.mean(2),percent,noise)\n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array[i,j]=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACCIntegG.npy', full_array)\n",
    "# xxx=np.load('ACCIntegG.npy')\n",
    "# plt.plot(xxx.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92252d9f",
   "metadata": {},
   "source": [
    "## SmoothGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc14fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SmoothGrad\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    # Get image and transform to tensor    \n",
    "    img = cv2.imread(os.path.join(imgdir, fname))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) \n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    input_img = pre_processing(img, True)\n",
    "    \n",
    "    output = model(input_img)\n",
    "    pred_index = np.argmax(output.data.cpu().numpy())\n",
    "    smooth_grad = SmoothGrad(\n",
    "        pretrained_model=model,\n",
    "        cuda=True,\n",
    "        n_samples=1000,\n",
    "        magnitude=True)\n",
    "    smooth_saliency = smooth_grad(input_img, index=None)\n",
    "\n",
    "    input_img = pre_processing(img, True)  \n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            noise=torch.randn(input_img.shape)\n",
    "            mask_,masked_img=createmaskedimage(input_img,smooth_saliency.sum(0),percent,noise)\n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_smooth[i,j]=1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd383c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACCSmoothG.npy', full_array_smooth)\n",
    "# xxx=np.load('ACCSmoothG.npy')\n",
    "# plt.plot(xxx.mean(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c61bd3",
   "metadata": {},
   "source": [
    "## Guided Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a8b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Guided BackProp\n",
    "full_array_GBP=torch.zeros((len(files),len(percent_list)))\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    # Get image and transform to tensor    \n",
    "    img = cv2.imread(os.path.join(imgdir, fname))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) \n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    input_img = pre_processing(img, True)\n",
    "    \n",
    "    output = model(input_img)\n",
    "    pred_index = np.argmax(output.data.cpu().numpy())\n",
    "\n",
    "    guided_grad = GuidedBackpropGrad(\n",
    "        pretrained_model=model, cuda=True)\n",
    "    \n",
    "    guided_saliency = guided_grad(input_img, index=None)\n",
    "    input_img = pre_processing(img, True)   \n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            noise=torch.randn(input_img.shape)\n",
    "            mask_,masked_img=createmaskedimage(input_img,guided_saliency.sum(0),percent,noise)\n",
    "\n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_GBP[i,j]=1        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACCGuidedBP.npy', full_array_GBP)\n",
    "xxx=np.load('ACCGuidedBP.npy')\n",
    "plt.plot(xxx.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82415d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker(mask,percent):\n",
    "    if percent==0:\n",
    "        return 99999999\n",
    "    elif percent==1:\n",
    "#         print(\"right\")\n",
    "        return -9999999\n",
    "    mask_open=[mask[0].reshape(-1)]\n",
    "    for i in range(len(mask[1])):\n",
    "        mask_open.append(mask[1][i].reshape(-1))\n",
    "    final_mask_open=torch.cat(mask_open,0).detach().cpu().numpy()\n",
    "    final_mask_open=final_mask_open.reshape(-1,1) # 60000 X 1\n",
    "    noise_symmet=torch.randn(final_mask_open.shape).numpy()*0.000000001\n",
    "    topk_idx=k_largest_index_argsort(noise_symmet+final_mask_open,int(final_mask_open.shape[0]*percent))\n",
    "    return(final_mask_open[topk_idx[-1][0],topk_idx[-1][1]])\n",
    "\n",
    "def createmaskedwavelt(wavelet,grad_mask,mark):\n",
    "    \n",
    "\n",
    "#     print(\"look-\",wavelet.shape,mask.shape)\n",
    "    noise=(torch.randn(wavelet.shape).to(device)*(torch.std(wavelet)).to(device))+torch.mean(wavelet).to(device)\n",
    "    new_wavelet=wavelet*(grad_mask>=mark)+noise.to(device)*((grad_mask<mark))\n",
    "    return(mask,new_wavelet.float())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da33fc6",
   "metadata": {},
   "source": [
    "## CartoonX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartoonX\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    x = Image.open(os.path.join(imgdir, fname))\n",
    "    x = transforms.ToTensor()(x)\n",
    "    x = transforms.Resize(size=(256,256))(x)\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    input_img=x.detach()\n",
    "    # classifiy image\n",
    "    output = model(x)\n",
    "    pred = nn.Softmax(dim=1)(output).max(1)[1].item() \n",
    "\n",
    "    # set CartoonX hyperparameters\n",
    "    HPARAMS ={\"wave\": \"db3\", \"mode\": \"zero\", \"J\": 5,\n",
    "              \"l1lambda\": 10, \"step_size\": 1e-3,\n",
    "              \"num_steps\": 100,  \"batch_size\": 16,\n",
    "              \"distortion_measure\": \"label\"} \n",
    "\n",
    "    # get Cartoon RDE \n",
    "    cartoonX = CartoonX(model=model, device=device,return_mask=True, **HPARAMS)\n",
    "    explanation,mask = cartoonX(x, pred)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            yl, yh = cartoonX.forward_dwt(x) \n",
    "            markz=marker(mask,percent)\n",
    "            _,obf_yl = createmaskedwavelt(yl,mask[0],markz)\n",
    "            obf_yh = []\n",
    "            for count, y in enumerate(yh):\n",
    "\n",
    "                obf_yh.append(createmaskedwavelt(yh[count],mask[1][count],markz)[1])\n",
    "            z = cartoonX.inverse_dwt((obf_yl,obf_yh))\n",
    "            masked_img = z.clamp(0,1) \n",
    "    \n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_cartoon[i,j]=1       \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7382a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACcartoon.npy', full_array_cartoon)\n",
    "# xxx=np.load('ACcartoon.npy')\n",
    "# plt.plot(xxx.mean(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f94f8",
   "metadata": {},
   "source": [
    "## Random Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random wavelet\n",
    "\n",
    "\n",
    "\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    x = Image.open(os.path.join(imgdir, fname))\n",
    "    x = transforms.ToTensor()(x)\n",
    "    x = transforms.Resize(size=(256,256))(x)\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    input_img=x\n",
    "    # classifiy image\n",
    "    output = model(x)\n",
    "    pred = nn.Softmax(dim=1)(output).max(1)[1].item() \n",
    "\n",
    "    # set CartoonX hyperparameters\n",
    "    HPARAMS ={\"wave\": \"db3\", \"mode\": \"zero\", \"J\": 5,\n",
    "              \"l1lambda\": 20, \"step_size\": 1e-3,\n",
    "              \"num_steps\": 100,  \"batch_size\": 16,\n",
    "              \"distortion_measure\": \"label\"} \n",
    "\n",
    "    # get Cartoon RDE \n",
    "    cartoonX = CartoonX(model=model, device=device,return_mask=True, **HPARAMS)\n",
    "    explanation,mask = cartoonX(x, pred)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mask[0]=torch.randn(mask[0].shape).to(device)\n",
    "        for dd in range(len(mask[1])):\n",
    "            mask[1][dd]=torch.randn(mask[1][dd].shape).to(device)\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            yl, yh = cartoonX.forward_dwt(x) \n",
    "            markz=marker(mask,percent)\n",
    "            _,obf_yl = createmaskedwavelt(yl,mask[0],markz)\n",
    "            obf_yh = []\n",
    "            for count, y in enumerate(yh):\n",
    "\n",
    "                obf_yh.append(createmaskedwavelt(yh[count],mask[1][count],markz)[1])\n",
    "            z = cartoonX.inverse_dwt((obf_yl,obf_yh))\n",
    "            masked_img = z.clamp(0,1) \n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_randomwavelet[i,j]=1        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACrandomwavelet.npy', full_array_randomwavelet)\n",
    "# xxx=np.load('ACrandomwavelet.npy')\n",
    "# plt.plot(xxx.mean(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb3353",
   "metadata": {},
   "source": [
    "## Random Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f97db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Pixel\n",
    "full_array_randompixel=torch.zeros((len(files),len(percent_list)))\n",
    "\n",
    "\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    # Get image and transform to tensor    \n",
    "    img = cv2.imread(os.path.join(imgdir, fname))\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) \n",
    "    img = img[:, :, (2, 1, 0)]\n",
    "    input_img = pre_processing(img, True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            noise=torch.randn(input_img.shape)\n",
    "            mask_,masked_img=createmaskedimage(input_img,np.random.randn(256,256),percent,noise)\n",
    "            \n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_randompixel[i,j]=1               \n",
    "            \n",
    "#             full_array_randompixel[i,j]=((F.softmax(model(input_img),1)-F.softmax(model(masked_img.float()),1))**2).sum()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d38559",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACrandompixel.npy', full_array_randompixel)\n",
    "# xxx=np.load('ACrandompixel.npy')\n",
    "# plt.plot(xxx.mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a7d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449a4f63",
   "metadata": {},
   "source": [
    "## Pixel RDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49387cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPARAMS_PIXEL_RDE['num_steps']=100\n",
    "# HPARAMS_PIXEL_RDE['l1lambda']=8\n",
    "# HPARAMS_PIXEL_RDE['step_size']=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pixel RDE\n",
    "full_array_pixelRDE=torch.zeros((len(files),len(percent_list)))\n",
    "\n",
    "for i,fname in enumerate(files):\n",
    "    print(f\"Processing file: {fname}\")\n",
    "    x = Image.open(os.path.join(imgdir, fname))\n",
    "    x = transforms.ToTensor()(x)\n",
    "    x = transforms.Resize(size=(256,256))(x)\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    \n",
    "    input_img = Image.open(os.path.join(imgdir, fname))\n",
    "    input_img = transforms.ToTensor()(input_img)\n",
    "    input_img = transforms.Resize(size=(256,256))(input_img)\n",
    "    input_img = input_img.to(device).unsqueeze(0)\n",
    "    \n",
    "    # classifiy image\n",
    "    output = model(x)\n",
    "    pred = nn.Softmax(dim=1)(output).max(1)[1].item() \n",
    "    pixelRDE = PixelRDE(model=model, device=device, **HPARAMS_PIXEL_RDE)\n",
    "    mask = pixelRDE(x, pred)    \n",
    "    mask=mask.cpu().numpy()\n",
    "    with torch.no_grad():\n",
    "        for j,percent in enumerate(percent_list):\n",
    "            noise=torch.randn(input_img.shape)\n",
    "            mask_,masked_img=createmaskedimage(input_img,mask,percent,noise)\n",
    "            \n",
    "            if torch.argmax(model(input_img),1)==torch.argmax(model(masked_img.float()),1):\n",
    "\n",
    "                full_array_pixelRDE[i,j]=1              \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2525dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ACpixelrde.npy', full_array_pixelRDE)\n",
    "# xxx=np.load('ACpixelrde.npy')\n",
    "# plt.plot(xxx.mean(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
